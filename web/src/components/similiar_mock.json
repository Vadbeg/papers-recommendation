[
  {
    "id": "automated-bridge-component-recognition-using",
    "title": "Automated Bridge Component Recognition using Video Data",
    "abstract": "This paper investigates the automated recognition of structural bridge\ncomponents using video data. Although understanding video data for structural\ninspections is straightforward for human inspectors, the implementation of the\nsame task using machine learning methods has not been fully realized. In\nparticular, single-frame image processing techniques, such as convolutional\nneural networks (CNNs), are not expected to identify structural components\naccurately when the image is a close-up view, lacking contextual information\nregarding where on the structure the image originates. Inspired by the\nsignificant progress in video processing techniques, this study investigates\nautomated bridge component recognition using video data, where the information\nfrom the past frames is used to augment the understanding of the current frame.\nA new simulated video dataset is created to train the machine learning\nalgorithms. Then, convolutional Neural Networks (CNNs) with recurrent\narchitectures are designed and applied to implement the automated bridge\ncomponent recognition task. Results are presented for simulated video data, as\nwell as video collected in the field.",
    "paper_dist": 1.292181241052402
  },
  {
    "id": "optimizing-the-trade-off-between-single-stage",
    "title": "Optimizing the Trade-off between Single-Stage and Two-Stage Object Detectors using Image Difficulty Prediction",
    "abstract": "There are mainly two types of state-of-the-art object detectors. On one hand,\nwe have two-stage detectors, such as Faster R-CNN (Region-based Convolutional\nNeural Networks) or Mask R-CNN, that (i) use a Region Proposal Network to\ngenerate regions of interests in the first stage and (ii) send the region\nproposals down the pipeline for object classification and bounding-box\nregression. Such models reach the highest accuracy rates, but are typically\nslower. On the other hand, we have single-stage detectors, such as YOLO (You\nOnly Look Once) and SSD (Singe Shot MultiBox Detector), that treat object\ndetection as a simple regression problem by taking an input image and learning\nthe class probabilities and bounding box coordinates. Such models reach lower\naccuracy rates, but are much faster than two-stage object detectors. In this\npaper, we propose to use an image difficulty predictor to achieve an optimal\ntrade-off between accuracy and speed in object detection. The image difficulty\npredictor is applied on the test images to split them into easy versus hard\nimages. Once separated, the easy images are sent to the faster single-stage\ndetector, while the hard images are sent to the more accurate two-stage\ndetector. Our experiments on PASCAL VOC 2007 show that using image difficulty\ncompares favorably to a random split of the images. Our method is flexible, in\nthat it allows to choose a desired threshold for splitting the images into easy\nversus hard.",
    "paper_dist": 1.330165598266123
  },
  {
    "id": "dynamical-isometry-and-a-mean-field-theory-of-2",
    "title": "Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks",
    "abstract": "In recent years, state-of-the-art methods in computer vision have utilized\nincreasingly deep convolutional neural network architectures (CNNs), with some\nof the most successful models employing hundreds or even thousands of layers. A\nvariety of pathologies such as vanishing/exploding gradients make training such\ndeep networks challenging. While residual connections and batch normalization\ndo enable training at these depths, it has remained unclear whether such\nspecialized architecture designs are truly necessary to train deep CNNs. In\nthis work, we demonstrate that it is possible to train vanilla CNNs with ten\nthousand layers or more simply by using an appropriate initialization scheme.\nWe derive this initialization scheme theoretically by developing a mean field\ntheory for signal propagation and by characterizing the conditions for\ndynamical isometry, the equilibration of singular values of the input-output\nJacobian matrix. These conditions require that the convolution operator be an\northogonal transformation in the sense that it is norm-preserving. We present\nan algorithm for generating such random initial orthogonal convolution kernels\nand demonstrate empirically that they enable efficient training of extremely\ndeep architectures.",
    "paper_dist": 1.335863426979793
  },
  {
    "id": "sample-dropout-for-audio-scene-classification",
    "title": "Sample Dropout for Audio Scene Classification Using Multi-Scale Dense Connected Convolutional Neural Network",
    "abstract": "Acoustic scene classification is an intricate problem for a machine. As an\nemerging field of research, deep Convolutional Neural Networks (CNN) achieve\nconvincing results. In this paper, we explore the use of multi-scale Dense\nconnected convolutional neural network (DenseNet) for the classification task,\nwith the goal to improve the classification performance as multi-scale features\ncan be extracted from the time-frequency representation of the audio signal. On\nthe other hand, most of previous CNN-based audio scene classification\napproaches aim to improve the classification accuracy, by employing different\nregularization techniques, such as the dropout of hidden units and data\naugmentation, to reduce overfitting. It is widely known that outliers in the\ntraining set have a high negative influence on the trained model, and culling\nthe outliers may improve the classification performance, while it is often\nunder-explored in previous studies. In this paper, inspired by the silence\nremoval in the speech signal processing, a novel sample dropout approach is\nproposed, which aims to remove outliers in the training dataset. Using the\nDCASE 2017 audio scene classification datasets, the experimental results\ndemonstrates the proposed multi-scale DenseNet providing a superior performance\nthan the traditional single-scale DenseNet, while the sample dropout method can\nfurther improve the classification robustness of multi-scale DenseNet.",
    "paper_dist": 1.3404793955901932
  }
]